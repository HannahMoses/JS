version control hints

VCS version control system
SVC sub version control


A major issue that people encounter is that they need to collaborate with developers
 on other systems. To deal with this problem, 
Centralized Version Control Systems (CVCSs) were developed. 

	These systems (such as CVS, Subversion, and Perforce) have a single server that 
	contains all the versioned files, and a number of clients that check out files from that
	 central place. For many years, this has been the standard for version control.

DISADVANTAGE of CVC
	If the centralized server  goes down for an hour, then during that hour nobody can 
	collaborate at all or save versioned changes to anything they’re working on. If the hard
	 disk the central database is on becomes corrupted, and proper backups haven’t 
	been kept, you lose absolutely everything — the entire history of the project except 
	whatever single snapshots people happen to have on their local machines.

DVCS Distributed Version Control Systems
	Distributed Version Control Systems (DVCSs) step in. In a DVCS (such as 
	Git, Mercurial, Bazaar or Darcs), clients don’t just check out the latest 
	snapshot of the files; rather, they fully mirror the repository, including its full 
	history. Thus, if any server dies, and these systems were collaborating via
	 that server, any of the client repositories can be copied back up to the
	 server to restore it. Every clone is really a full backup of all the data.

HISTORY 1991
	 https://git-scm.com/book/en/v2/Getting-Started-A-Short-History-of-Git

	Since its birth in 2005, Git has evolved and matured to be easy to use and
	 yet retain these initial qualities:
	Speed
	Simple design
	Strong support for non-linear development (thousands of parallel branches)
	Fully distributed
	Able to handle large projects like  Linux kernel efficiently (speed and data size)
.
	Git is amazingly fast, it’s very efficient with large projects, and it has an 
	incredible branching system for non-linear development (See Git Branching).
                                    ..=....
	Git began with a bit of creative destruction and fiery controversy.

	The Linux kernel is an open source software project of fairly large scope. 
	For most of the lifetime of the Linux kernel maintenance (1991–2002), 
	changes to the software were passed around as patches and archived files
	. In 2002, the Linux kernel project began using a proprietary DVCS called
	 BitKeeper.

	In 2005, the relationship between the community that developed the Linux 
	kernel and the commercial company that developed BitKeeper broke down,
	 and the tool’s free-of-charge status was revoked. This prompted the 
	Linux development community (and in particular Linus Torvalds, the creator
	 of Linux) to develop their own tool based on some of the lessons they 
	learned while using BitKeeper.

DIFFERENCE between GIT and other version control systems
	Git thinks of its data more like a series of snapshots of a miniature filesystem.
	CVS, Subversion, Perforce, Bazaar) store information 
	as a list of file-based changes.
	They think of the information they store as a set of files and the changes 
	made to each file over time (this is commonly described as delta-based 
	version control).

	Git thinks of its data more like a series of snapshots of a miniature filesystem.
	This makes Git more like a mini filesystem with some incredibly powerful tools
	 built on top of it, rather than simply a VCS.  
	With Git, every time you commit, or save the state of your project, Git basically
	 takes a picture of what all your files look like at that moment and stores a
	 reference to that snapshot. To be efficient, if files have not changed, Git
	 doesn’t store the file again, just a link to the previous identical file it has
	 already stored. Git thinks about its data more like a stream of snapshots.


	Most operations in Git need only local files and resources to operate —
	 generally no information is needed from another computer on your network
	In other CVCs, most operations have that network latency overhead.

	OFFLINE efficiency
	 if you’re offline or off VPN and want to do a little work, you can commit 
	(to your local copy, remember?) until you get to a network connection to 
	upload. If you go home and can’t get your VPN client working properly, you
	 can still work. In many other systems, doing so is either impossible or 
	painful. 
                 In Perforce, you can’t do much when you aren’t connected to the server.
                 In Subversion and CVS, you can edit files, but you can’t commit changes to
	 your database (because your database is offline). 

	GIT INTEGRITY
	Git stores everything in its database not by file name but by the hash value of its contents.
	You can’t lose information in transit or get file corruption without Git being
	 able to detect it.
	 After you commit a snapshot into Git, it is very difficult to lose, especially if
	 you regularly push your database to another repository.


	Everything in Git is checksummed before it is stored and is then referred to 
	by that checksum. This means it’s impossible to change the contents of any
	 file or directory without Git knowing about it. 

SHA- 1 hash
	The mechanism that Git uses for this checksumming is called a SHA-1 hash.
	 This is a 40-character string composed of hexadecimal characters
	 (0–9 and a–f) and calculated based on the contents of a file or directory 
	structure in Git. A SHA-1 hash looks something like this:


	24b9da6552252987aa493b52f8696cd6d3b00373
	We will see these hash values all over the place in Git because it uses them
	 so much.
 	In fact, Git stores everything in its database not by file name but by the hash
	 value of its contents.

The Three States
Pay attention now — here is the main thing to remember about Git if you want the rest of your learning process to go smoothly. Git has three main states that your files can reside in: modified, staged, and committed:

Modified means that you have changed the file but have not committed it to your database yet.

Staged means that you have marked a modified file in its current version to go into your next commit snapshot.

Committed means that the data is safely stored in your local database.

This leads us to the three main sections of a Git project: the working tree, the staging area, and the Git directory.
The working tree is a single checkout of one version of the project. These files are pulled out of the compressed database in the Git directory and placed on disk for you to use or modify.

The staging area is a file, generally contained in your Git directory, that stores information about what will go into your next commit. Its technical name in Git parlance is the “index”, but the phrase “staging area” works just as well.

The Git directory is where Git stores the metadata and object database for your project. This is the most important part of Git, and it is what is copied when you clone a repository from another computer.

The basic Git workflow goes something like this:

You modify files in your working tree.

You selectively stage just those changes you want to be part of your next commit, which adds only those changes to the staging area.

You do a commit, which takes the files as they are in the staging area and stores that snapshot permanently to your Git directory.

If a particular version of a file is in the Git directory, it’s considered committed. If it has been modified and was added to the staging area, it is staged. And if it was changed since it was checked out but has not been staged, it is modified. In Git Basics, you’ll learn more about these states and how you can either take advantage of them or skip the staged part entirely.




